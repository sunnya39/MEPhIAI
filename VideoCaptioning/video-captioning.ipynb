{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11884666,"sourceType":"datasetVersion","datasetId":7469621}],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!cp -r /kaggle/input/video-caption/test_videos ./","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T10:33:00.677305Z","iopub.execute_input":"2025-06-01T10:33:00.677458Z","iopub.status.idle":"2025-06-01T10:33:13.030837Z","shell.execute_reply.started":"2025-06-01T10:33:00.677444Z","shell.execute_reply":"2025-06-01T10:33:13.030059Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"!cp -r /kaggle/input/video-caption/train_videos ./","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T10:33:13.031736Z","iopub.execute_input":"2025-06-01T10:33:13.032014Z","iopub.status.idle":"2025-06-01T10:33:27.907893Z","shell.execute_reply.started":"2025-06-01T10:33:13.031980Z","shell.execute_reply":"2025-06-01T10:33:27.907144Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"!cp -r /kaggle/input/video-caption/test.csv ./","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T10:33:27.909769Z","iopub.execute_input":"2025-06-01T10:33:27.909995Z","iopub.status.idle":"2025-06-01T10:33:28.037554Z","shell.execute_reply.started":"2025-06-01T10:33:27.909972Z","shell.execute_reply":"2025-06-01T10:33:28.036659Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"!cp -r /kaggle/input/video-caption/train.csv ./","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T10:33:28.038517Z","iopub.execute_input":"2025-06-01T10:33:28.038771Z","iopub.status.idle":"2025-06-01T10:33:28.183369Z","shell.execute_reply.started":"2025-06-01T10:33:28.038737Z","shell.execute_reply":"2025-06-01T10:33:28.182472Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"!pip install opencv-python","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T10:33:28.184358Z","iopub.execute_input":"2025-06-01T10:33:28.184551Z","iopub.status.idle":"2025-06-01T10:33:31.731250Z","shell.execute_reply.started":"2025-06-01T10:33:28.184516Z","shell.execute_reply":"2025-06-01T10:33:31.730356Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\nRequirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.2->opencv-python) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.2->opencv-python) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.2->opencv-python) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.2->opencv-python) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.2->opencv-python) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.2->opencv-python) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.21.2->opencv-python) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.21.2->opencv-python) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.21.2->opencv-python) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.21.2->opencv-python) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.21.2->opencv-python) (2024.2.0)\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import shutil\nimport tqdm\nimport numpy as np\nimport cv2\nimport os\nimport torchvision\nfrom torch import nn\n\nimport json\nimport random\nimport pandas as pd\nimport torch\nfrom tokenizers import Tokenizer, models, pre_tokenizers, trainers, processors\nfrom tokenizers.normalizers import Sequence, Lowercase, NFD, StripAccents\nfrom PIL import Image\nimport torch.optim as optim","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T10:33:31.732421Z","iopub.execute_input":"2025-06-01T10:33:31.733101Z","iopub.status.idle":"2025-06-01T10:33:38.944202Z","shell.execute_reply.started":"2025-06-01T10:33:31.733044Z","shell.execute_reply":"2025-06-01T10:33:38.943630Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"def video_to_frames(video_path, output_dir):\n    if os.path.exists(output_dir):\n        for file in os.listdir(output_dir):\n            os.remove(os.path.join(output_dir, file))\n    else:\n        os.makedirs(output_dir)\n    count = 0\n    image_list = []\n    # Path to video file\n    cap = cv2.VideoCapture(video_path)\n    while cap.isOpened():\n        ret, frame = cap.read()\n        if ret is False:\n            break\n        cv2.imwrite(os.path.join(output_dir, 'frame%d.jpg' % count), frame)\n        image_list.append(os.path.join(output_dir, 'frame%d.jpg' % count))\n        count += 1\n\n    cap.release()\n    cv2.destroyAllWindows()\n    return image_list","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T10:33:38.944878Z","iopub.execute_input":"2025-06-01T10:33:38.945203Z","iopub.status.idle":"2025-06-01T10:33:38.950408Z","shell.execute_reply.started":"2025-06-01T10:33:38.945185Z","shell.execute_reply":"2025-06-01T10:33:38.949755Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"import torch\n\ndef model_cnn_load():\n# Load pretrained VGG16\n    model = torchvision.models.vgg16(weights='IMAGENET1K_V1')\n    \n    # Remove the last classification layer (keep up to the second-to-last layer)\n    model = nn.Sequential(*list(model.children())[:-1])  # Removes final Linear layer\n    \n    return model\n\ndef load_image(path):\n    img = cv2.imread(path)\n    img = cv2.resize(img, (224, 224))\n    return img\n\ndef extract_features(video, model):\n    video_id = video.split(\".\")[0]\n    print(f'Processing video {video}')\n\n    image_list = video_to_frames(f'train_videos/{video}', 'temporary_images')\n    samples = np.round(np.linspace(\n        0, len(image_list) - 1, 80)).astype(int)\n    image_list = [image_list[sample] for sample in samples]\n    images = torch.zeros((len(image_list), 3, 224, 224), dtype=torch.float32)\n    mean = torch.tensor([0.485, 0.456, 0.406]).view(1, 3, 1, 1)\n    std = torch.tensor([0.229, 0.224, 0.225]).view(1, 3, 1, 1)\n    for i in range(len(image_list)):\n        img = load_image(image_list[i])\n        img_np = np.array(img)\n        img_np = img_np.transpose(2, 0, 1)\n        img = torch.from_numpy(img_np).float()\n        img = img.unsqueeze(0) / 255.0\n        img = (img - mean) / std\n        images[i] = img.squeeze(0)\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    images = images.to(device)\n    model = model.to(device)\n    model.eval()\n    with torch.no_grad():\n        fc_feats = model(images)\n        # img_feats = fc_feats.detach().cpu().numpy()\n    shutil.rmtree('temporary_images')\n    return fc_feats\n\ndef extract_feats_pretrained_cnn():\n    model = model_cnn_load()\n    print('Model loaded')\n\n    if not os.path.isdir(os.path.join('features_dir')):\n        os.mkdir('features_dir')\n\n    video_list = os.listdir('train_videos')\n    for video in video_list:\n        outfile = os.path.join('features_dir', video.split(\".\")[0] + '.pt')\n        img_feats = extract_features(video, model)\n        torch.save(img_feats, outfile)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T10:33:38.951207Z","iopub.execute_input":"2025-06-01T10:33:38.951423Z","iopub.status.idle":"2025-06-01T10:33:38.968089Z","shell.execute_reply.started":"2025-06-01T10:33:38.951406Z","shell.execute_reply":"2025-06-01T10:33:38.967406Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"class HuggingFaceTokenizedPreprocessor:\n    def __init__(self, validation_split=0.2, max_seq_length=30):\n        self.validation_split = validation_split\n        self.max_seq_length = max_seq_length\n        self.x_data = {}  # Store video features\n\n        self.special_tokens=[\n                (\"[BOS]\", 1),\n                (\"[EOS]\", 2),\n                (\"[UNK]\", 3),\n                (\"[PAD]\", 0),\n                (\".\", 4),\n                (\",\", 5)\n            ]\n        self.initial_vocab = {token: idx for token, idx in self.special_tokens}\n        \n        # Initialize HuggingFace tokenizer\n        self.tokenizer = Tokenizer(models.WordLevel(unk_token=\"[UNK]\", vocab=self.initial_vocab))\n        self.tokenizer.normalizer = Sequence([NFD(), Lowercase(), StripAccents()])\n        self.tokenizer.pre_tokenizer = pre_tokenizers.WhitespaceSplit()\n        self.tokenizer.post_processor = processors.TemplateProcessing(\n            single=\"[BOS] $A [EOS]\",\n            special_tokens=[\n                (\"[BOS]\", 1),\n                (\"[EOS]\", 2),\n                (\"[UNK]\", 3),\n                (\"[PAD]\", 0),\n                (\".\", 4),\n                (\",\", 5)\n            ]\n        )\n        self.special_tokens_string = [token for token, _ in self.special_tokens]\n\n        for token, idx in self.special_tokens:\n            self.tokenizer.add_tokens([token])\n        \n    def preprocess_text(self, caption):\n        \"\"\"Preprocess text keeping punctuation as separate tokens\"\"\"\n        # Add space around punctuation for proper splitting\n        caption = caption.replace('.', ' . ').replace(',', ' , ')\n        return caption.strip()\n    \n    def build_vocabulary(self, df):\n        \"\"\"Train the tokenizer on the dataset\"\"\"\n        trainer = trainers.WordLevelTrainer(\n            vocab_size=1000,\n            special_tokens=self.special_tokens_string,\n            min_frequency=2,\n            initial_alphabet=list(self.initial_vocab.keys())\n        )\n        \n        # Prepare text iterator\n        def get_texts():\n            for caption in df['caption']:\n                yield self.preprocess_text(caption)\n                \n        self.tokenizer.train_from_iterator(get_texts(), trainer=trainer)\n        \n    def preprocessing(self):\n        \"\"\"Load and preprocess training data from CSV\"\"\"\n        train_df = pd.read_csv('train.csv')\n\n\n        video_list = (os.listdir('train_videos'))\n        train_df = train_df[train_df['file_name'].isin(video_list)]\n        \n        \n        # Build vocabulary\n        self.build_vocabulary(train_df)\n        \n        # Process captions and filter by length\n        train_list = []\n        for _, row in train_df.iterrows():\n            processed_text = self.preprocess_text(row['caption'])\n            encoding = self.tokenizer.encode(processed_text)\n            \n            # Filter by content length (excluding special tokens and punctuation)\n            content_tokens = [\n                t for t in encoding.tokens \n                if t not in self.special_tokens_string\n            ]\n            \n            train_list.append({\n                'caption_ids': encoding.ids,\n                'id': row['file_name'].split('.')[0],\n                'index': row['index']\n            })\n        \n        # Shuffle and split data\n        random.shuffle(train_list)\n        split_idx = int(len(train_list) * self.validation_split)\n        validation_list = train_list[:split_idx]\n        training_list = train_list[split_idx:]\n        \n        # Load video features\n        for filename in os.listdir('features_dir'):\n            if filename.endswith('.pt'):\n                video_id = filename[:-3]\n                features = torch.load(os.path.join('features_dir', filename))\n                self.x_data[video_id] = features.float()\n                # features = np.load(os.path.join('features_dir', filename), allow_pickle=True)\n                # self.x_data[video_id] = torch.from_numpy(features).float()\n        \n        return training_list, validation_list\n    \n    def text_to_ids(self, text):\n        \"\"\"Convert text to token IDs\"\"\"\n        processed_text = self.preprocess_text(text)\n        return self.tokenizer.encode(processed_text).ids\n    \n    def ids_to_text(self, ids):\n        \"\"\"Convert token IDs back to text\"\"\"\n        return self.tokenizer.decode(ids)\n\n    def save(self):\n        \"\"\"Save the tokenizer and preprocessor config\"\"\"\n        import json\n        \n        # Create directory if it doesn't exist\n        \n        # Save tokenizer\n        self.tokenizer.save(\"tokenizer.json\")\n        \n        config = {\n            \"special_tokens\": self.special_tokens,\n            \"special_tokens_string\": self.special_tokens_string\n        }\n        \n        with open(\"config.json\", \"w\") as f:\n            json.dump(config, f)\n            \n    @classmethod\n    def load(cls):\n        \"\"\"Load a saved tokenizer and preprocessor\"\"\"\n        import json\n        \n        # Load config\n        with open(\"config.json\", \"r\") as f:\n            config = json.load(f)\n        \n        preprocessor = cls()\n        \n        # Load tokenizer\n        \n        preprocessor.tokenizer = Tokenizer.from_file(\"tokenizer.json\")\n        preprocessor.special_tokens = config[\"special_tokens\"]\n        preprocessor.special_tokens_string = config[\"special_tokens_string\"]\n        \n        return preprocessor","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T10:33:38.970452Z","iopub.execute_input":"2025-06-01T10:33:38.970631Z","iopub.status.idle":"2025-06-01T10:33:38.985167Z","shell.execute_reply.started":"2025-06-01T10:33:38.970618Z","shell.execute_reply":"2025-06-01T10:33:38.984552Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"from torch.nn.utils.rnn import pad_sequence\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn.functional as F\n\nclass VideoCaptionDataset(Dataset):\n    def __init__(self, training_list, x_data, tokenizer, max_length, num_decoder_tokens, device):\n        \"\"\"\n        PyTorch Dataset for video captioning\n        \n        Args:\n            training_list: List of training samples (caption, video_id)\n            x_data: Dictionary of video features {video_id: features}\n            tokenizer: HuggingFace tokenizer\n            max_length: Maximum sequence length\n            num_decoder_tokens: Vocabulary size\n        \"\"\"\n        self.training_list = training_list\n        self.x_data = x_data\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n        self.num_decoder_tokens = num_decoder_tokens\n        self.device = device\n        \n        # Preprocess all data\n        self.video_ids = []\n        self.caption_ids = []\n\n        for train_data in training_list:\n            train_values_list = list(train_data.values())\n            self.video_ids.append(train_values_list[1])\n            self.caption_ids.append(train_values_list[0])\n                \n    def __len__(self):\n        return len(self.training_list)\n    \n    def __getitem__(self, idx):\n        # Get video features\n        video_features = self.x_data[self.video_ids[idx]].float().to(self.device)\n        \n        # Process caption\n        caption_ids = self.caption_ids[idx]\n        \n        # Pad/truncate sequence\n        if len(caption_ids) <= self.max_length:\n            pad_len = (self.max_length + 1) - len(caption_ids)\n            caption_ids = caption_ids[:-1] + [self.tokenizer.token_to_id(\"[PAD]\")] * pad_len + [self.tokenizer.token_to_id(\"[EOS]\")] \n        elif len(caption_ids) > self.max_length:\n            caption_ids = caption_ids[:self.max_length] + [self.tokenizer.token_to_id(\"[EOS]\")]\n        \n        # Convert to tensors\n        caption_tensor = torch.tensor(caption_ids, device=self.device)\n        one_hot = F.one_hot(caption_tensor, num_classes=1000).float()\n        \n        # Create decoder input (shifted right) and target (shifted left)\n        decoder_input = one_hot[:-1]\n        decoder_target = one_hot[1:]\n\n        return {\n            'encoder_input': video_features,\n            'decoder_input': decoder_input,\n            'decoder_target': decoder_target,\n            'video_id': self.video_ids[idx]\n        }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T10:33:38.985800Z","iopub.execute_input":"2025-06-01T10:33:38.986045Z","iopub.status.idle":"2025-06-01T10:33:38.999650Z","shell.execute_reply.started":"2025-06-01T10:33:38.986029Z","shell.execute_reply":"2025-06-01T10:33:38.999025Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"def collate_fn(batch):\n    \"\"\"\n    Custom collate function to pad sequences to same length and create batches\n    \n    Args:\n        batch: List of samples from VideoCaptionDataset\n    \n    Returns:\n        Dictionary of batched tensors with shapes:\n        - encoder_input: [batch_size, seq_len, input_size]\n        - decoder_input: [batch_size, seq_len, num_decoder_tokens]\n        - decoder_target: [batch_size, seq_len, num_decoder_tokens]\n        - video_ids: List of video IDs\n    \"\"\"\n    # Get all encoder inputs and find max sequence length\n    encoder_inputs = [item['encoder_input'] for item in batch]\n    decoder_inputs = [item['decoder_input'] for item in batch]\n    decoder_targets = [item['decoder_target'] for item in batch]\n    video_ids = [item['video_id'] for item in batch]\n\n    encoder_input_batch = torch.stack(encoder_inputs, dim=0)\n    \n    # Stack decoder inputs and targets (they should already be the same length from dataset)\n    decoder_input_batch = torch.stack(decoder_inputs, dim=0)\n    decoder_target_batch = torch.stack(decoder_targets, dim=0)\n    \n    return {\n        'encoder_input': encoder_input_batch,\n        'decoder_input': decoder_input_batch,\n        'decoder_target': decoder_target_batch,\n        'video_id': video_ids\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T10:33:39.000303Z","iopub.execute_input":"2025-06-01T10:33:39.000523Z","iopub.status.idle":"2025-06-01T10:33:39.013212Z","shell.execute_reply.started":"2025-06-01T10:33:39.000507Z","shell.execute_reply":"2025-06-01T10:33:39.012563Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"from torch.optim.lr_scheduler import ReduceLROnPlateau\nfrom tqdm import tqdm\n\nclass Seq2SeqModel(nn.Module):\n    def __init__(self):\n        super(Seq2SeqModel, self).__init__()\n        \n        # Encoder\n        self.encoder_lstm = nn.LSTM(\n            input_size=512,\n            hidden_size=512,\n            batch_first=True\n        )\n\n        # Decoder\n        self.decoder_lstm = nn.LSTM(\n            input_size=1000,\n            hidden_size=512,\n            batch_first=True\n        )\n        self.decoder_dense = nn.Linear(512, 1000)\n        \n    def forward(self, encoder_inputs, decoder_inputs, encoder_hidden, encoder_cell):\n        # Encoder\n        _, (hidden, cell) = self.encoder_lstm(encoder_inputs, (encoder_hidden, encoder_cell))\n        \n        # Decoder\n        decoder_outputs, _ = self.decoder_lstm(\n            decoder_inputs, \n            (hidden, cell)\n        )\n        \n        decoder_outputs = self.decoder_dense(decoder_outputs)\n        return decoder_outputs\n\nclass VideoCaptionTrainer:\n    def __init__(self):\n        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        self.model = Seq2SeqModel().to(self.device)\n        \n    def train_model(self):\n        # Load datasets\n        preprocessor = HuggingFaceTokenizedPreprocessor()\n        training_list, validation_list = preprocessor.preprocessing()\n        \n        train_dataset = VideoCaptionDataset(\n                            training_list=training_list,\n                            x_data=preprocessor.x_data,\n                            tokenizer=preprocessor.tokenizer,\n                            max_length=30,\n                            num_decoder_tokens=1000,\n                            device=self.device\n                        )\n        val_dataset = VideoCaptionDataset(\n                            training_list=validation_list,\n                            x_data=preprocessor.x_data,\n                            tokenizer=preprocessor.tokenizer,\n                            max_length=30,\n                            num_decoder_tokens=1000,\n                            device=self.device\n                        )\n        train_loader = DataLoader(\n                            train_dataset,\n                            batch_size=8,\n                            shuffle=False,\n                            num_workers=0,\n                            collate_fn=collate_fn\n                        )\n        val_loader = DataLoader(\n                            val_dataset,\n                            batch_size=8,\n                            shuffle=False,\n                            num_workers=0,\n                            collate_fn=collate_fn\n                        )\n        \n        # Loss and optimizer\n        criterion = nn.CrossEntropyLoss()  # Ignore padding index\n        optimizer = optim.Adam(self.model.parameters(), lr=0.001)\n        scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5)\n        \n        # Early stopping\n        best_val_loss = float('inf')\n        patience = 5\n        patience_counter = 0\n        \n        for epoch in range(150):\n            # Training\n            self.model.train()\n            train_loss = 0.0\n            for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n                encoder_input = batch['encoder_input']\n                decoder_input = batch['decoder_input']\n                decoder_target = batch['decoder_target']\n                batch_size = encoder_input.shape[0]\n\n                pool = nn.AdaptiveAvgPool2d((1, 1))\n                encoder_input = pool(encoder_input).squeeze(-1).squeeze(-1)\n\n                encoder_input.to(self.device)\n                # decoder_input.to(self.device)\n                decoder_target.to(self.device)\n\n                h = torch.zeros(1, batch_size, 512).to(self.device)\n                c = torch.zeros(1, batch_size, 512).to(self.device)\n                \n                optimizer.zero_grad()\n                outputs = self.model(encoder_input, decoder_input.float().to(self.device), h, c)\n\n                # targets = decoder_target\n                \n                loss = criterion(outputs, decoder_target)\n                loss.backward()\n                optimizer.step()\n                \n                train_loss += loss.item()\n            \n            # Validation\n            self.model.eval()\n            val_loss = 0.0\n            with torch.no_grad():\n                for batch in val_loader:\n                    encoder_input = batch['encoder_input']\n                    decoder_input = batch['decoder_input']\n                    decoder_target = batch['decoder_target']\n                    batch_size = encoder_input.shape[0]\n\n                    pool = nn.AdaptiveAvgPool2d((1, 1))\n                    encoder_input = pool(encoder_input).squeeze(-1).squeeze(-1)\n    \n                    encoder_input.to(self.device)\n                    decoder_input.to(self.device)\n                    decoder_target.to(self.device)\n    \n                    h = torch.zeros(1, batch_size, 512).to(self.device)\n                    c = torch.zeros(1, batch_size, 512).to(self.device)\n                    \n                    outputs = self.model(encoder_input, decoder_input.float(), h, c)\n                    targets = decoder_target\n                    \n                    val_loss += criterion(outputs, targets).item()\n            \n            # Calculate average losses\n            train_loss /= len(train_loader)\n            val_loss /= len(val_loader)\n            \n            print(f\"Epoch {epoch+1}: Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n            \n            # Learning rate scheduling\n            scheduler.step(val_loss)\n            \n            # Early stopping\n            if val_loss < best_val_loss:\n                best_val_loss = val_loss\n                patience_counter = 0\n                torch.save(self.model.encoder_lstm.state_dict(), 'encoder_model_weights.pth')\n                torch.save(self.model.decoder_lstm.state_dict(), 'decoder_model_weights.pth')\n                preprocessor.save()\n                \n            else:\n                patience_counter += 1\n                if patience_counter >= patience:\n                    print(\"Early stopping triggered\")\n                    break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T10:33:39.014671Z","iopub.execute_input":"2025-06-01T10:33:39.015184Z","iopub.status.idle":"2025-06-01T10:33:39.030458Z","shell.execute_reply.started":"2025-06-01T10:33:39.015157Z","shell.execute_reply":"2025-06-01T10:33:39.029794Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"extract_feats_pretrained_cnn()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T10:36:50.414381Z","iopub.execute_input":"2025-06-01T10:36:50.414664Z","iopub.status.idle":"2025-06-01T10:49:18.224011Z","shell.execute_reply.started":"2025-06-01T10:36:50.414641Z","shell.execute_reply":"2025-06-01T10:49:18.223451Z"}},"outputs":[{"name":"stdout","text":"Model loaded\nProcessing video 158.mp4\nProcessing video 366.mp4\nProcessing video 550.mp4\nProcessing video 444.mp4\nProcessing video 602.mp4\nProcessing video 506.mp4\nProcessing video 370.mp4\nProcessing video 28.mp4\nProcessing video 84.mp4\nProcessing video 116.mp4\nProcessing video 540.mp4\nProcessing video 291.mp4\nProcessing video 363.mp4\nProcessing video 97.mp4\nProcessing video 340.mp4\nProcessing video 490.mp4\nProcessing video 503.mp4\nProcessing video 43.mp4\nProcessing video 412.mp4\nProcessing video 111.mp4\nProcessing video 18.mp4\nProcessing video 79.mp4\nProcessing video 278.mp4\nProcessing video 449.mp4\nProcessing video 437.mp4\nProcessing video 122.mp4\nProcessing video 509.mp4\nProcessing video 225.mp4\nProcessing video 362.mp4\nProcessing video 522.mp4\nProcessing video 388.mp4\nProcessing video 539.mp4\nProcessing video 151.mp4\nProcessing video 533.mp4\nProcessing video 57.mp4\nProcessing video 379.mp4\nProcessing video 246.mp4\nProcessing video 162.mp4\nProcessing video 504.mp4\nProcessing video 402.mp4\nProcessing video 314.mp4\nProcessing video 61.mp4\nProcessing video 348.mp4\nProcessing video 98.mp4\nProcessing video 572.mp4\nProcessing video 252.mp4\nProcessing video 108.mp4\nProcessing video 351.mp4\nProcessing video 374.mp4\nProcessing video 175.mp4\nProcessing video 523.mp4\nProcessing video 60.mp4\nProcessing video 167.mp4\nProcessing video 330.mp4\nProcessing video 212.mp4\nProcessing video 250.mp4\nProcessing video 217.mp4\nProcessing video 317.mp4\nProcessing video 168.mp4\nProcessing video 427.mp4\nProcessing video 64.mp4\nProcessing video 279.mp4\nProcessing video 576.mp4\nProcessing video 272.mp4\nProcessing video 518.mp4\nProcessing video 321.mp4\nProcessing video 494.mp4\nProcessing video 501.mp4\nProcessing video 450.mp4\nProcessing video 319.mp4\nProcessing video 432.mp4\nProcessing video 232.mp4\nProcessing video 277.mp4\nProcessing video 163.mp4\nProcessing video 205.mp4\nProcessing video 383.mp4\nProcessing video 344.mp4\nProcessing video 596.mp4\nProcessing video 287.mp4\nProcessing video 74.mp4\nProcessing video 125.mp4\nProcessing video 491.mp4\nProcessing video 251.mp4\nProcessing video 569.mp4\nProcessing video 36.mp4\nProcessing video 177.mp4\nProcessing video 443.mp4\nProcessing video 453.mp4\nProcessing video 45.mp4\nProcessing video 71.mp4\nProcessing video 295.mp4\nProcessing video 536.mp4\nProcessing video 328.mp4\nProcessing video 371.mp4\nProcessing video 470.mp4\nProcessing video 551.mp4\nProcessing video 254.mp4\nProcessing video 580.mp4\nProcessing video 126.mp4\nProcessing video 409.mp4\nProcessing video 12.mp4\nProcessing video 554.mp4\nProcessing video 396.mp4\nProcessing video 433.mp4\nProcessing video 46.mp4\nProcessing video 376.mp4\nProcessing video 11.mp4\nProcessing video 117.mp4\nProcessing video 367.mp4\nProcessing video 353.mp4\nProcessing video 154.mp4\nProcessing video 259.mp4\nProcessing video 159.mp4\nProcessing video 59.mp4\nProcessing video 310.mp4\nProcessing video 145.mp4\nProcessing video 478.mp4\nProcessing video 484.mp4\nProcessing video 558.mp4\nProcessing video 113.mp4\nProcessing video 405.mp4\nProcessing video 93.mp4\nProcessing video 238.mp4\nProcessing video 101.mp4\nProcessing video 302.mp4\nProcessing video 75.mp4\nProcessing video 284.mp4\nProcessing video 65.mp4\nProcessing video 135.mp4\nProcessing video 464.mp4\nProcessing video 4.mp4\nProcessing video 161.mp4\nProcessing video 183.mp4\nProcessing video 415.mp4\nProcessing video 235.mp4\nProcessing video 6.mp4\nProcessing video 209.mp4\nProcessing video 434.mp4\nProcessing video 468.mp4\nProcessing video 263.mp4\nProcessing video 459.mp4\nProcessing video 299.mp4\nProcessing video 192.mp4\nProcessing video 222.mp4\nProcessing video 118.mp4\nProcessing video 8.mp4\nProcessing video 216.mp4\nProcessing video 142.mp4\nProcessing video 573.mp4\nProcessing video 179.mp4\nProcessing video 41.mp4\nProcessing video 404.mp4\nProcessing video 139.mp4\nProcessing video 564.mp4\nProcessing video 204.mp4\nProcessing video 207.mp4\nProcessing video 471.mp4\nProcessing video 578.mp4\nProcessing video 191.mp4\nProcessing video 485.mp4\nProcessing video 583.mp4\nProcessing video 269.mp4\nProcessing video 303.mp4\nProcessing video 403.mp4\nProcessing video 337.mp4\nProcessing video 561.mp4\nProcessing video 482.mp4\nProcessing video 514.mp4\nProcessing video 38.mp4\nProcessing video 530.mp4\nProcessing video 474.mp4\nProcessing video 469.mp4\nProcessing video 240.mp4\nProcessing video 24.mp4\nProcessing video 292.mp4\nProcessing video 103.mp4\nProcessing video 368.mp4\nProcessing video 546.mp4\nProcessing video 293.mp4\nProcessing video 30.mp4\nProcessing video 334.mp4\nProcessing video 419.mp4\nProcessing video 483.mp4\nProcessing video 305.mp4\nProcessing video 308.mp4\nProcessing video 587.mp4\nProcessing video 423.mp4\nProcessing video 335.mp4\nProcessing video 169.mp4\nProcessing video 242.mp4\nProcessing video 547.mp4\nProcessing video 525.mp4\nProcessing video 85.mp4\nProcessing video 338.mp4\nProcessing video 16.mp4\nProcessing video 313.mp4\nProcessing video 187.mp4\nProcessing video 556.mp4\nProcessing video 414.mp4\nProcessing video 336.mp4\nProcessing video 537.mp4\nProcessing video 520.mp4\nProcessing video 322.mp4\nProcessing video 429.mp4\nProcessing video 600.mp4\nProcessing video 567.mp4\nProcessing video 264.mp4\nProcessing video 52.mp4\nProcessing video 445.mp4\nProcessing video 392.mp4\nProcessing video 92.mp4\nProcessing video 82.mp4\nProcessing video 95.mp4\nProcessing video 426.mp4\nProcessing video 274.mp4\nProcessing video 430.mp4\nProcessing video 224.mp4\nProcessing video 343.mp4\nProcessing video 324.mp4\nProcessing video 400.mp4\nProcessing video 389.mp4\nProcessing video 493.mp4\nProcessing video 180.mp4\nProcessing video 133.mp4\nProcessing video 390.mp4\nProcessing video 544.mp4\nProcessing video 345.mp4\nProcessing video 208.mp4\nProcessing video 354.mp4\nProcessing video 597.mp4\nProcessing video 276.mp4\nProcessing video 589.mp4\nProcessing video 593.mp4\nProcessing video 146.mp4\nProcessing video 312.mp4\nProcessing video 245.mp4\nProcessing video 398.mp4\nProcessing video 134.mp4\nProcessing video 256.mp4\nProcessing video 99.mp4\nProcessing video 106.mp4\nProcessing video 452.mp4\nProcessing video 273.mp4\nProcessing video 199.mp4\nProcessing video 394.mp4\nProcessing video 268.mp4\nProcessing video 143.mp4\nProcessing video 229.mp4\nProcessing video 188.mp4\nProcessing video 290.mp4\nProcessing video 294.mp4\nProcessing video 257.mp4\nProcessing video 447.mp4\nProcessing video 568.mp4\nProcessing video 527.mp4\nProcessing video 575.mp4\nProcessing video 215.mp4\nProcessing video 553.mp4\nProcessing video 512.mp4\nProcessing video 346.mp4\nProcessing video 526.mp4\nProcessing video 360.mp4\nProcessing video 165.mp4\nProcessing video 592.mp4\nProcessing video 511.mp4\nProcessing video 499.mp4\nProcessing video 86.mp4\nProcessing video 58.mp4\nProcessing video 131.mp4\nProcessing video 480.mp4\nProcessing video 164.mp4\nProcessing video 552.mp4\nProcessing video 529.mp4\nProcessing video 557.mp4\nProcessing video 372.mp4\nProcessing video 489.mp4\nProcessing video 148.mp4\nProcessing video 171.mp4\nProcessing video 5.mp4\nProcessing video 304.mp4\nProcessing video 150.mp4\nProcessing video 438.mp4\nProcessing video 56.mp4\nProcessing video 76.mp4\nProcessing video 102.mp4\nProcessing video 170.mp4\nProcessing video 555.mp4\nProcessing video 407.mp4\nProcessing video 227.mp4\nProcessing video 562.mp4\nProcessing video 595.mp4\nProcessing video 473.mp4\nProcessing video 298.mp4\nProcessing video 377.mp4\nProcessing video 508.mp4\nProcessing video 560.mp4\nProcessing video 184.mp4\nProcessing video 22.mp4\nProcessing video 37.mp4\nProcessing video 81.mp4\nProcessing video 10.mp4\nProcessing video 140.mp4\nProcessing video 566.mp4\nProcessing video 129.mp4\nProcessing video 442.mp4\nProcessing video 585.mp4\nProcessing video 601.mp4\nProcessing video 446.mp4\nProcessing video 3.mp4\nProcessing video 9.mp4\nProcessing video 260.mp4\nProcessing video 500.mp4\nProcessing video 584.mp4\nProcessing video 307.mp4\nProcessing video 548.mp4\nProcessing video 70.mp4\nProcessing video 454.mp4\nProcessing video 341.mp4\nProcessing video 51.mp4\nProcessing video 230.mp4\nProcessing video 172.mp4\nProcessing video 515.mp4\nProcessing video 296.mp4\nProcessing video 386.mp4\nProcessing video 289.mp4\nProcessing video 181.mp4\nProcessing video 115.mp4\nProcessing video 441.mp4\nProcessing video 96.mp4\nProcessing video 105.mp4\nProcessing video 399.mp4\nProcessing video 176.mp4\nProcessing video 531.mp4\nProcessing video 258.mp4\nProcessing video 262.mp4\nProcessing video 401.mp4\nProcessing video 391.mp4\nProcessing video 69.mp4\nProcessing video 114.mp4\nProcessing video 332.mp4\nProcessing video 333.mp4\nProcessing video 297.mp4\nProcessing video 137.mp4\nProcessing video 189.mp4\nProcessing video 559.mp4\nProcessing video 364.mp4\nProcessing video 439.mp4\nProcessing video 282.mp4\nProcessing video 42.mp4\nProcessing video 121.mp4\nProcessing video 48.mp4\nProcessing video 586.mp4\nProcessing video 373.mp4\nProcessing video 201.mp4\nProcessing video 288.mp4\nProcessing video 384.mp4\nProcessing video 517.mp4\nProcessing video 90.mp4\nProcessing video 67.mp4\nProcessing video 73.mp4\nProcessing video 185.mp4\nProcessing video 356.mp4\nProcessing video 166.mp4\nProcessing video 571.mp4\nProcessing video 221.mp4\nProcessing video 32.mp4\nProcessing video 72.mp4\nProcessing video 233.mp4\nProcessing video 350.mp4\nProcessing video 220.mp4\nProcessing video 315.mp4\nProcessing video 271.mp4\nProcessing video 416.mp4\nProcessing video 80.mp4\nProcessing video 62.mp4\nProcessing video 387.mp4\nProcessing video 53.mp4\nProcessing video 21.mp4\nProcessing video 237.mp4\nProcessing video 265.mp4\nProcessing video 301.mp4\nProcessing video 123.mp4\nProcessing video 320.mp4\nProcessing video 349.mp4\nProcessing video 542.mp4\nProcessing video 26.mp4\nProcessing video 138.mp4\nProcessing video 406.mp4\nProcessing video 543.mp4\nProcessing video 519.mp4\nProcessing video 267.mp4\nProcessing video 147.mp4\nProcessing video 355.mp4\nProcessing video 451.mp4\nProcessing video 329.mp4\nProcessing video 226.mp4\nProcessing video 393.mp4\nProcessing video 261.mp4\nProcessing video 456.mp4\nProcessing video 395.mp4\nProcessing video 375.mp4\nProcessing video 365.mp4\nProcessing video 193.mp4\nProcessing video 234.mp4\nProcessing video 50.mp4\nProcessing video 247.mp4\nProcessing video 361.mp4\nProcessing video 521.mp4\nProcessing video 120.mp4\nProcessing video 347.mp4\nProcessing video 206.mp4\nProcessing video 448.mp4\nProcessing video 241.mp4\nProcessing video 156.mp4\nProcessing video 144.mp4\nProcessing video 582.mp4\nProcessing video 590.mp4\nProcessing video 466.mp4\nProcessing video 413.mp4\nProcessing video 248.mp4\nProcessing video 425.mp4\nProcessing video 318.mp4\nProcessing video 283.mp4\nProcessing video 149.mp4\nProcessing video 44.mp4\nProcessing video 486.mp4\nProcessing video 327.mp4\nProcessing video 196.mp4\nProcessing video 27.mp4\nProcessing video 352.mp4\nProcessing video 109.mp4\nProcessing video 428.mp4\nProcessing video 538.mp4\nProcessing video 236.mp4\nProcessing video 182.mp4\nProcessing video 198.mp4\nProcessing video 119.mp4\nProcessing video 323.mp4\nProcessing video 100.mp4\nProcessing video 218.mp4\nProcessing video 358.mp4\nProcessing video 239.mp4\nProcessing video 49.mp4\nProcessing video 487.mp4\nProcessing video 178.mp4\nProcessing video 467.mp4\nProcessing video 541.mp4\nProcessing video 488.mp4\nProcessing video 462.mp4\nProcessing video 281.mp4\nProcessing video 55.mp4\nProcessing video 15.mp4\nProcessing video 380.mp4\nProcessing video 35.mp4\nProcessing video 31.mp4\nProcessing video 152.mp4\nProcessing video 507.mp4\nProcessing video 231.mp4\nProcessing video 270.mp4\nProcessing video 29.mp4\nProcessing video 157.mp4\nProcessing video 463.mp4\nProcessing video 455.mp4\nProcessing video 7.mp4\nProcessing video 498.mp4\nProcessing video 563.mp4\nProcessing video 397.mp4\nProcessing video 253.mp4\nProcessing video 23.mp4\nProcessing video 431.mp4\nProcessing video 532.mp4\nProcessing video 174.mp4\nProcessing video 535.mp4\nProcessing video 516.mp4\nProcessing video 141.mp4\nProcessing video 475.mp4\nProcessing video 577.mp4\nProcessing video 422.mp4\nProcessing video 598.mp4\nProcessing video 306.mp4\nProcessing video 13.mp4\nProcessing video 155.mp4\nProcessing video 255.mp4\nProcessing video 457.mp4\nProcessing video 211.mp4\nProcessing video 496.mp4\nProcessing video 492.mp4\nProcessing video 249.mp4\nProcessing video 124.mp4\nProcessing video 599.mp4\nProcessing video 311.mp4\nProcessing video 2.mp4\nProcessing video 89.mp4\nProcessing video 210.mp4\nProcessing video 173.mp4\nProcessing video 17.mp4\nProcessing video 34.mp4\nProcessing video 528.mp4\nProcessing video 244.mp4\nProcessing video 94.mp4\nProcessing video 410.mp4\nProcessing video 458.mp4\nProcessing video 440.mp4\nProcessing video 579.mp4\nProcessing video 228.mp4\nProcessing video 594.mp4\nProcessing video 25.mp4\nProcessing video 20.mp4\nProcessing video 417.mp4\nProcessing video 91.mp4\nProcessing video 88.mp4\nProcessing video 588.mp4\nProcessing video 581.mp4\nProcessing video 477.mp4\nProcessing video 342.mp4\nProcessing video 54.mp4\nProcessing video 33.mp4\nProcessing video 0.mp4\nProcessing video 461.mp4\nProcessing video 378.mp4\nProcessing video 549.mp4\nProcessing video 110.mp4\nProcessing video 545.mp4\nProcessing video 357.mp4\nProcessing video 591.mp4\nProcessing video 497.mp4\nProcessing video 479.mp4\nProcessing video 14.mp4\nProcessing video 40.mp4\nProcessing video 160.mp4\nProcessing video 502.mp4\nProcessing video 339.mp4\nProcessing video 266.mp4\nProcessing video 460.mp4\nProcessing video 213.mp4\nProcessing video 130.mp4\nProcessing video 465.mp4\nProcessing video 408.mp4\nProcessing video 574.mp4\nProcessing video 476.mp4\nProcessing video 136.mp4\nProcessing video 286.mp4\nProcessing video 104.mp4\nProcessing video 243.mp4\nProcessing video 325.mp4\nProcessing video 63.mp4\nProcessing video 481.mp4\nProcessing video 420.mp4\nProcessing video 194.mp4\nProcessing video 513.mp4\nProcessing video 112.mp4\nProcessing video 316.mp4\nProcessing video 39.mp4\nProcessing video 472.mp4\nProcessing video 411.mp4\nProcessing video 1.mp4\nProcessing video 47.mp4\nProcessing video 78.mp4\nProcessing video 219.mp4\nProcessing video 510.mp4\nProcessing video 280.mp4\nProcessing video 153.mp4\nProcessing video 203.mp4\nProcessing video 77.mp4\nProcessing video 107.mp4\nProcessing video 132.mp4\nProcessing video 19.mp4\nProcessing video 223.mp4\nProcessing video 195.mp4\nProcessing video 66.mp4\nProcessing video 275.mp4\nProcessing video 436.mp4\nProcessing video 385.mp4\nProcessing video 300.mp4\nProcessing video 200.mp4\nProcessing video 128.mp4\nProcessing video 534.mp4\nProcessing video 68.mp4\nProcessing video 285.mp4\nProcessing video 495.mp4\nProcessing video 87.mp4\nProcessing video 421.mp4\nProcessing video 202.mp4\nProcessing video 369.mp4\nProcessing video 382.mp4\nProcessing video 214.mp4\nProcessing video 326.mp4\nProcessing video 570.mp4\nProcessing video 359.mp4\nProcessing video 190.mp4\nProcessing video 381.mp4\nProcessing video 197.mp4\nProcessing video 565.mp4\nProcessing video 505.mp4\nProcessing video 127.mp4\nProcessing video 331.mp4\nProcessing video 309.mp4\nProcessing video 186.mp4\nProcessing video 418.mp4\nProcessing video 435.mp4\nProcessing video 424.mp4\nProcessing video 83.mp4\nProcessing video 524.mp4\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"preprocessor = HuggingFaceTokenizedPreprocessor()\ntraining_list, validation_list = preprocessor.preprocessing()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T10:49:18.225219Z","iopub.execute_input":"2025-06-01T10:49:18.225442Z","iopub.status.idle":"2025-06-01T10:49:22.641808Z","shell.execute_reply.started":"2025-06-01T10:49:18.225425Z","shell.execute_reply":"2025-06-01T10:49:22.641250Z"}},"outputs":[{"name":"stdout","text":"Ignored unknown kwargs option initial_alphabet\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"trainer = VideoCaptionTrainer()\ntrainer.train_model()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T10:49:22.642511Z","iopub.execute_input":"2025-06-01T10:49:22.642726Z","iopub.status.idle":"2025-06-01T10:49:48.736172Z","shell.execute_reply.started":"2025-06-01T10:49:22.642709Z","shell.execute_reply":"2025-06-01T10:49:48.735572Z"}},"outputs":[{"name":"stdout","text":"Ignored unknown kwargs option initial_alphabet\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1: 100%|██████████| 61/61 [00:01<00:00, 43.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1: Train Loss: 0.0938, Val Loss: 0.0905\nThe OrderedVocab you are attempting to save contains holes for indices [4, 5], your vocabulary could be corrupted !\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2: 100%|██████████| 61/61 [00:01<00:00, 60.77it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2: Train Loss: 0.0877, Val Loss: 0.0884\nThe OrderedVocab you are attempting to save contains holes for indices [4, 5], your vocabulary could be corrupted !\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3: 100%|██████████| 61/61 [00:01<00:00, 60.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3: Train Loss: 0.0835, Val Loss: 0.0855\nThe OrderedVocab you are attempting to save contains holes for indices [4, 5], your vocabulary could be corrupted !\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4: 100%|██████████| 61/61 [00:01<00:00, 60.51it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4: Train Loss: 0.0788, Val Loss: 0.0822\nThe OrderedVocab you are attempting to save contains holes for indices [4, 5], your vocabulary could be corrupted !\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5: 100%|██████████| 61/61 [00:01<00:00, 60.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5: Train Loss: 0.0730, Val Loss: 0.0783\nThe OrderedVocab you are attempting to save contains holes for indices [4, 5], your vocabulary could be corrupted !\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6: 100%|██████████| 61/61 [00:01<00:00, 60.02it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6: Train Loss: 0.0683, Val Loss: 0.0770\nThe OrderedVocab you are attempting to save contains holes for indices [4, 5], your vocabulary could be corrupted !\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7: 100%|██████████| 61/61 [00:01<00:00, 60.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7: Train Loss: 0.0640, Val Loss: 0.0757\nThe OrderedVocab you are attempting to save contains holes for indices [4, 5], your vocabulary could be corrupted !\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8: 100%|██████████| 61/61 [00:01<00:00, 59.99it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8: Train Loss: 0.0603, Val Loss: 0.0746\nThe OrderedVocab you are attempting to save contains holes for indices [4, 5], your vocabulary could be corrupted !\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9: 100%|██████████| 61/61 [00:01<00:00, 59.66it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9: Train Loss: 0.0575, Val Loss: 0.0745\nThe OrderedVocab you are attempting to save contains holes for indices [4, 5], your vocabulary could be corrupted !\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10: 100%|██████████| 61/61 [00:01<00:00, 59.72it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 10: Train Loss: 0.0550, Val Loss: 0.0720\nThe OrderedVocab you are attempting to save contains holes for indices [4, 5], your vocabulary could be corrupted !\n","output_type":"stream"},{"name":"stderr","text":"Epoch 11: 100%|██████████| 61/61 [00:01<00:00, 59.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 11: Train Loss: 0.0508, Val Loss: 0.0728\n","output_type":"stream"},{"name":"stderr","text":"Epoch 12: 100%|██████████| 61/61 [00:01<00:00, 59.07it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 12: Train Loss: 0.0482, Val Loss: 0.0722\n","output_type":"stream"},{"name":"stderr","text":"Epoch 13: 100%|██████████| 61/61 [00:01<00:00, 58.83it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 13: Train Loss: 0.0460, Val Loss: 0.0716\nThe OrderedVocab you are attempting to save contains holes for indices [4, 5], your vocabulary could be corrupted !\n","output_type":"stream"},{"name":"stderr","text":"Epoch 14: 100%|██████████| 61/61 [00:01<00:00, 59.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 14: Train Loss: 0.0439, Val Loss: 0.0733\n","output_type":"stream"},{"name":"stderr","text":"Epoch 15: 100%|██████████| 61/61 [00:01<00:00, 58.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 15: Train Loss: 0.0416, Val Loss: 0.0722\n","output_type":"stream"},{"name":"stderr","text":"Epoch 16: 100%|██████████| 61/61 [00:01<00:00, 58.60it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 16: Train Loss: 0.0397, Val Loss: 0.0719\n","output_type":"stream"},{"name":"stderr","text":"Epoch 17: 100%|██████████| 61/61 [00:01<00:00, 58.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 17: Train Loss: 0.0374, Val Loss: 0.0728\n","output_type":"stream"},{"name":"stderr","text":"Epoch 18: 100%|██████████| 61/61 [00:01<00:00, 58.84it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 18: Train Loss: 0.0361, Val Loss: 0.0744\nEarly stopping triggered\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"def extract_test_features(video, model):\n    video_id = video.split(\".\")[0]\n    print(f'Processing video {video}')\n\n    image_list = video_to_frames(f'test_videos/{video}', 'test_temporary_images')\n    samples = np.round(np.linspace(\n        0, len(image_list) - 1, 80)).astype(int)\n    image_list = [image_list[sample] for sample in samples]\n    images = torch.zeros((len(image_list), 3, 224, 224), dtype=torch.float32)\n    mean = torch.tensor([0.485, 0.456, 0.406]).view(1, 3, 1, 1)\n    std = torch.tensor([0.229, 0.224, 0.225]).view(1, 3, 1, 1)\n    for i in range(len(image_list)):\n        img = load_image(image_list[i])\n        img_np = np.array(img)\n        img_np = img_np.transpose(2, 0, 1)\n        img = torch.from_numpy(img_np).float()\n        img = img.unsqueeze(0) / 255.0\n        img = (img - mean) / std\n        images[i] = img.squeeze(0)\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    images = images.to(device)\n    model = model.to(device)\n    model.eval()\n    with torch.no_grad():\n        fc_feats = model(images)\n        # img_feats = fc_feats.cpu().numpy()\n    shutil.rmtree('test_temporary_images')\n    return fc_feats\n\ndef extract_test_feats_pretrained_cnn():\n    model = model_cnn_load()\n    print('Model loaded')\n\n    if not os.path.isdir(os.path.join('test_features_dir')):\n        os.mkdir('test_features_dir')\n\n    video_list = os.listdir('test_videos')\n    for video in video_list:\n        outfile = os.path.join('test_features_dir', video.split(\".\")[0] + '.pt')\n        img_feats = extract_test_features(video, model)\n        torch.save(img_feats, outfile)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T11:06:25.362981Z","iopub.execute_input":"2025-06-01T11:06:25.363759Z","iopub.status.idle":"2025-06-01T11:06:25.372949Z","shell.execute_reply.started":"2025-06-01T11:06:25.363734Z","shell.execute_reply":"2025-06-01T11:06:25.372249Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"def get_test_data():\n    # Read test CSV\n    test_df = pd.read_csv('test.csv')\n    \n    test_features = []\n    test_ids = []\n    test_filenames = []\n    \n    for _, row in test_df.iterrows():\n        video_id = row['index']\n        filename = row['file_name']\n        feature_path = os.path.join('test_features_dir', filename.split(\".\")[0] + '.pt')\n        \n        if os.path.exists(feature_path):\n            # Load numpy array and convert to torch tensor\n            features = torch.load(feature_path)\n            test_features.append(features.float())\n            test_ids.append(video_id)\n            test_filenames.append(filename)\n\n    return test_features, test_ids, test_filenames","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T11:06:25.374650Z","iopub.execute_input":"2025-06-01T11:06:25.374879Z","iopub.status.idle":"2025-06-01T11:06:25.388778Z","shell.execute_reply.started":"2025-06-01T11:06:25.374862Z","shell.execute_reply":"2025-06-01T11:06:25.388203Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T11:20:38.861563Z","iopub.execute_input":"2025-06-01T11:20:38.861819Z","iopub.status.idle":"2025-06-01T11:20:38.865878Z","shell.execute_reply.started":"2025-06-01T11:20:38.861800Z","shell.execute_reply":"2025-06-01T11:20:38.865058Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"class Inference_Seq2SeqModel(nn.Module):\n    def __init__(self):\n        super(Inference_Seq2SeqModel, self).__init__()\n\n        # Encoder\n        self.encoder_lstm = nn.LSTM(\n            input_size=512,\n            hidden_size=512,\n            batch_first=True\n        )\n        \n        # Decoder\n        self.decoder_lstm = nn.LSTM(\n            input_size=1000,\n            hidden_size=512,\n            batch_first=True\n        )\n        self.decoder_dense = nn.Linear(512, 1000)\n\n        self.encoder_lstm.load_state_dict(torch.load('encoder_model_weights.pth'))\n        self.decoder_lstm.load_state_dict(torch.load('decoder_model_weights.pth'))\n        \n    def forward(self, encoder_inputs, decoder_inputs, encoder_hidden, encoder_cell):\n        _, (hidden, cell) = self.encoder_lstm(encoder_inputs, (encoder_hidden, encoder_cell))\n        \n        # Decoder\n        decoder_outputs, _ = self.decoder_lstm(\n            decoder_inputs, \n            (hidden, cell)\n        )\n        \n        decoder_outputs = self.decoder_dense(decoder_outputs)\n        return decoder_outputs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T11:06:25.389473Z","iopub.execute_input":"2025-06-01T11:06:25.389731Z","iopub.status.idle":"2025-06-01T11:06:25.400926Z","shell.execute_reply.started":"2025-06-01T11:06:25.389712Z","shell.execute_reply":"2025-06-01T11:06:25.400321Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"def greedy_search(loaded_array):\n    # Convert numpy array to tensor\n    input_tensor = loaded_array.mean(dim=[2, 3])\n    input_tensor = input_tensor.unsqueeze(0)\n    \n    # Initialize\n    _, (hidden, cell) = test_model.encoder_lstm(input_tensor.to(device))\n    decoder_input = torch.zeros((1, 1, 1000))  # (batch, seq_len, vocab_size)\n    decoder_input[0, 0, preprocessor.tokenizer.token_to_id(\"[BOS]\")] = 1\n    hidden.to(device)\n    cell.to(device)\n    \n    sentence = []\n    max_length = 30\n\n    prev_word_idx = -1\n    for _ in range(max_length):\n        # Decoder step\n        output, (hidden, cell) = test_model.decoder_lstm(decoder_input.to(device), (hidden, cell))\n\n        output = test_model.decoder_dense(output)\n        \n        # Get most likely word\n        word_idx = torch.argmax(output).item()  # (1, 1, vocab_size) -> scalar\n        \n        # Stop if EOS token\n        if word_idx == preprocessor.tokenizer.token_to_id(\"[EOS]\"):\n            break\n            \n        # Skip if padding token\n        if word_idx == preprocessor.tokenizer.token_to_id(\"[PAD]\"):\n            continue\n\n        if prev_word_idx != word_idx:\n            word = preprocessor.tokenizer.id_to_token(word_idx)\n            \n            if word is not None:\n                sentence.append(word)\n            \n        # Next input is current output\n        decoder_input = torch.zeros_like(decoder_input)\n        decoder_input[0, 0, word_idx] = 1\n\n        prev_word_idx = word_idx\n\n    caption = ' '.join(sentence)\n    caption = caption.replace(' .', '.').replace(' ,', ',')\n    \n    return caption.strip()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T11:25:00.436882Z","iopub.execute_input":"2025-06-01T11:25:00.437185Z","iopub.status.idle":"2025-06-01T11:25:00.444086Z","shell.execute_reply.started":"2025-06-01T11:25:00.437159Z","shell.execute_reply":"2025-06-01T11:25:00.443481Z"}},"outputs":[],"execution_count":44},{"cell_type":"code","source":"def test():\n    # # Load test data\n    # test_features, test_ids, test_filenames = self.get_test_data()\n    \n    predictions = []\n    \n    for idx, (features, video_id, filename) in enumerate(zip(test_features, test_ids, test_filenames)):\n        \n        # Generate caption\n        # start_time = time.time()\n        caption = greedy_search(features)\n        \n        # inference_time = time.time() - start_time\n        \n        predictions.append({\n            'index': video_id,\n            'file_name': filename,\n            'caption': caption\n        })\n\n    # Save to CSV\n    pd.DataFrame(predictions).to_csv(\n        'submission.csv',\n        columns=['index', 'file_name', 'caption'],\n        index=False\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T11:06:25.414589Z","iopub.execute_input":"2025-06-01T11:06:25.414769Z","iopub.status.idle":"2025-06-01T11:06:25.425338Z","shell.execute_reply.started":"2025-06-01T11:06:25.414756Z","shell.execute_reply":"2025-06-01T11:06:25.424766Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"extract_test_feats_pretrained_cnn()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T11:06:25.467205Z","iopub.execute_input":"2025-06-01T11:06:25.467377Z","iopub.status.idle":"2025-06-01T11:18:02.650795Z","shell.execute_reply.started":"2025-06-01T11:06:25.467363Z","shell.execute_reply":"2025-06-01T11:18:02.650229Z"}},"outputs":[{"name":"stdout","text":"Model loaded\nProcessing video 158.mp4\nProcessing video 366.mp4\nProcessing video 444.mp4\nProcessing video 506.mp4\nProcessing video 370.mp4\nProcessing video 28.mp4\nProcessing video 84.mp4\nProcessing video 116.mp4\nProcessing video 291.mp4\nProcessing video 363.mp4\nProcessing video 97.mp4\nProcessing video 340.mp4\nProcessing video 490.mp4\nProcessing video 503.mp4\nProcessing video 43.mp4\nProcessing video 412.mp4\nProcessing video 111.mp4\nProcessing video 18.mp4\nProcessing video 79.mp4\nProcessing video 278.mp4\nProcessing video 449.mp4\nProcessing video 437.mp4\nProcessing video 122.mp4\nProcessing video 509.mp4\nProcessing video 225.mp4\nProcessing video 362.mp4\nProcessing video 388.mp4\nProcessing video 151.mp4\nProcessing video 57.mp4\nProcessing video 379.mp4\nProcessing video 246.mp4\nProcessing video 162.mp4\nProcessing video 504.mp4\nProcessing video 402.mp4\nProcessing video 314.mp4\nProcessing video 61.mp4\nProcessing video 348.mp4\nProcessing video 98.mp4\nProcessing video 252.mp4\nProcessing video 108.mp4\nProcessing video 351.mp4\nProcessing video 374.mp4\nProcessing video 175.mp4\nProcessing video 60.mp4\nProcessing video 167.mp4\nProcessing video 330.mp4\nProcessing video 212.mp4\nProcessing video 250.mp4\nProcessing video 217.mp4\nProcessing video 317.mp4\nProcessing video 168.mp4\nProcessing video 427.mp4\nProcessing video 64.mp4\nProcessing video 279.mp4\nProcessing video 272.mp4\nProcessing video 518.mp4\nProcessing video 321.mp4\nProcessing video 494.mp4\nProcessing video 501.mp4\nProcessing video 450.mp4\nProcessing video 319.mp4\nProcessing video 432.mp4\nProcessing video 232.mp4\nProcessing video 277.mp4\nProcessing video 163.mp4\nProcessing video 205.mp4\nProcessing video 383.mp4\nProcessing video 344.mp4\nProcessing video 287.mp4\nProcessing video 74.mp4\nProcessing video 125.mp4\nProcessing video 491.mp4\nProcessing video 251.mp4\nProcessing video 36.mp4\nProcessing video 177.mp4\nProcessing video 443.mp4\nProcessing video 453.mp4\nProcessing video 45.mp4\nProcessing video 71.mp4\nProcessing video 295.mp4\nProcessing video 328.mp4\nProcessing video 371.mp4\nProcessing video 470.mp4\nProcessing video 254.mp4\nProcessing video 126.mp4\nProcessing video 409.mp4\nProcessing video 12.mp4\nProcessing video 396.mp4\nProcessing video 433.mp4\nProcessing video 46.mp4\nProcessing video 376.mp4\nProcessing video 11.mp4\nProcessing video 117.mp4\nProcessing video 367.mp4\nProcessing video 353.mp4\nProcessing video 154.mp4\nProcessing video 259.mp4\nProcessing video 159.mp4\nProcessing video 59.mp4\nProcessing video 310.mp4\nProcessing video 145.mp4\nProcessing video 478.mp4\nProcessing video 484.mp4\nProcessing video 113.mp4\nProcessing video 405.mp4\nProcessing video 93.mp4\nProcessing video 238.mp4\nProcessing video 101.mp4\nProcessing video 302.mp4\nProcessing video 75.mp4\nProcessing video 284.mp4\nProcessing video 65.mp4\nProcessing video 135.mp4\nProcessing video 464.mp4\nProcessing video 4.mp4\nProcessing video 161.mp4\nProcessing video 183.mp4\nProcessing video 415.mp4\nProcessing video 235.mp4\nProcessing video 6.mp4\nProcessing video 209.mp4\nProcessing video 434.mp4\nProcessing video 468.mp4\nProcessing video 263.mp4\nProcessing video 459.mp4\nProcessing video 299.mp4\nProcessing video 192.mp4\nProcessing video 222.mp4\nProcessing video 118.mp4\nProcessing video 8.mp4\nProcessing video 216.mp4\nProcessing video 142.mp4\nProcessing video 179.mp4\nProcessing video 41.mp4\nProcessing video 404.mp4\nProcessing video 139.mp4\nProcessing video 204.mp4\nProcessing video 207.mp4\nProcessing video 471.mp4\nProcessing video 191.mp4\nProcessing video 485.mp4\nProcessing video 269.mp4\nProcessing video 303.mp4\nProcessing video 403.mp4\nProcessing video 337.mp4\nProcessing video 482.mp4\nProcessing video 514.mp4\nProcessing video 38.mp4\nProcessing video 474.mp4\nProcessing video 469.mp4\nProcessing video 240.mp4\nProcessing video 24.mp4\nProcessing video 292.mp4\nProcessing video 103.mp4\nProcessing video 368.mp4\nProcessing video 293.mp4\nProcessing video 30.mp4\nProcessing video 334.mp4\nProcessing video 419.mp4\nProcessing video 483.mp4\nProcessing video 305.mp4\nProcessing video 308.mp4\nProcessing video 423.mp4\nProcessing video 335.mp4\nProcessing video 169.mp4\nProcessing video 242.mp4\nProcessing video 85.mp4\nProcessing video 338.mp4\nProcessing video 16.mp4\nProcessing video 313.mp4\nProcessing video 187.mp4\nProcessing video 414.mp4\nProcessing video 336.mp4\nProcessing video 520.mp4\nProcessing video 322.mp4\nProcessing video 429.mp4\nProcessing video 264.mp4\nProcessing video 52.mp4\nProcessing video 445.mp4\nProcessing video 392.mp4\nProcessing video 92.mp4\nProcessing video 82.mp4\nProcessing video 95.mp4\nProcessing video 426.mp4\nProcessing video 274.mp4\nProcessing video 430.mp4\nProcessing video 224.mp4\nProcessing video 343.mp4\nProcessing video 324.mp4\nProcessing video 400.mp4\nProcessing video 389.mp4\nProcessing video 493.mp4\nProcessing video 180.mp4\nProcessing video 133.mp4\nProcessing video 390.mp4\nProcessing video 345.mp4\nProcessing video 208.mp4\nProcessing video 354.mp4\nProcessing video 276.mp4\nProcessing video 146.mp4\nProcessing video 312.mp4\nProcessing video 245.mp4\nProcessing video 398.mp4\nProcessing video 134.mp4\nProcessing video 256.mp4\nProcessing video 99.mp4\nProcessing video 106.mp4\nProcessing video 452.mp4\nProcessing video 273.mp4\nProcessing video 199.mp4\nProcessing video 394.mp4\nProcessing video 268.mp4\nProcessing video 143.mp4\nProcessing video 229.mp4\nProcessing video 188.mp4\nProcessing video 290.mp4\nProcessing video 294.mp4\nProcessing video 257.mp4\nProcessing video 447.mp4\nProcessing video 215.mp4\nProcessing video 512.mp4\nProcessing video 346.mp4\nProcessing video 360.mp4\nProcessing video 165.mp4\nProcessing video 511.mp4\nProcessing video 499.mp4\nProcessing video 86.mp4\nProcessing video 58.mp4\nProcessing video 131.mp4\nProcessing video 480.mp4\nProcessing video 164.mp4\nProcessing video 372.mp4\nProcessing video 489.mp4\nProcessing video 148.mp4\nProcessing video 171.mp4\nProcessing video 5.mp4\nProcessing video 304.mp4\nProcessing video 150.mp4\nProcessing video 438.mp4\nProcessing video 56.mp4\nProcessing video 76.mp4\nProcessing video 102.mp4\nProcessing video 170.mp4\nProcessing video 407.mp4\nProcessing video 227.mp4\nProcessing video 473.mp4\nProcessing video 298.mp4\nProcessing video 377.mp4\nProcessing video 508.mp4\nProcessing video 184.mp4\nProcessing video 22.mp4\nProcessing video 37.mp4\nProcessing video 81.mp4\nProcessing video 10.mp4\nProcessing video 140.mp4\nProcessing video 129.mp4\nProcessing video 442.mp4\nProcessing video 446.mp4\nProcessing video 3.mp4\nProcessing video 9.mp4\nProcessing video 260.mp4\nProcessing video 500.mp4\nProcessing video 307.mp4\nProcessing video 70.mp4\nProcessing video 454.mp4\nProcessing video 341.mp4\nProcessing video 51.mp4\nProcessing video 230.mp4\nProcessing video 172.mp4\nProcessing video 515.mp4\nProcessing video 296.mp4\nProcessing video 386.mp4\nProcessing video 289.mp4\nProcessing video 181.mp4\nProcessing video 115.mp4\nProcessing video 441.mp4\nProcessing video 96.mp4\nProcessing video 105.mp4\nProcessing video 399.mp4\nProcessing video 176.mp4\nProcessing video 258.mp4\nProcessing video 262.mp4\nProcessing video 401.mp4\nProcessing video 391.mp4\nProcessing video 69.mp4\nProcessing video 114.mp4\nProcessing video 332.mp4\nProcessing video 333.mp4\nProcessing video 297.mp4\nProcessing video 137.mp4\nProcessing video 189.mp4\nProcessing video 364.mp4\nProcessing video 439.mp4\nProcessing video 282.mp4\nProcessing video 42.mp4\nProcessing video 121.mp4\nProcessing video 48.mp4\nProcessing video 373.mp4\nProcessing video 201.mp4\nProcessing video 288.mp4\nProcessing video 384.mp4\nProcessing video 517.mp4\nProcessing video 90.mp4\nProcessing video 67.mp4\nProcessing video 73.mp4\nProcessing video 185.mp4\nProcessing video 356.mp4\nProcessing video 166.mp4\nProcessing video 221.mp4\nProcessing video 32.mp4\nProcessing video 72.mp4\nProcessing video 233.mp4\nProcessing video 350.mp4\nProcessing video 220.mp4\nProcessing video 315.mp4\nProcessing video 271.mp4\nProcessing video 416.mp4\nProcessing video 80.mp4\nProcessing video 62.mp4\nProcessing video 387.mp4\nProcessing video 53.mp4\nProcessing video 21.mp4\nProcessing video 237.mp4\nProcessing video 265.mp4\nProcessing video 301.mp4\nProcessing video 123.mp4\nProcessing video 320.mp4\nProcessing video 349.mp4\nProcessing video 26.mp4\nProcessing video 138.mp4\nProcessing video 406.mp4\nProcessing video 519.mp4\nProcessing video 267.mp4\nProcessing video 147.mp4\nProcessing video 355.mp4\nProcessing video 451.mp4\nProcessing video 329.mp4\nProcessing video 226.mp4\nProcessing video 393.mp4\nProcessing video 261.mp4\nProcessing video 456.mp4\nProcessing video 395.mp4\nProcessing video 375.mp4\nProcessing video 365.mp4\nProcessing video 193.mp4\nProcessing video 234.mp4\nProcessing video 50.mp4\nProcessing video 247.mp4\nProcessing video 361.mp4\nProcessing video 120.mp4\nProcessing video 347.mp4\nProcessing video 206.mp4\nProcessing video 448.mp4\nProcessing video 241.mp4\nProcessing video 156.mp4\nProcessing video 144.mp4\nProcessing video 466.mp4\nProcessing video 413.mp4\nProcessing video 248.mp4\nProcessing video 425.mp4\nProcessing video 318.mp4\nProcessing video 283.mp4\nProcessing video 149.mp4\nProcessing video 44.mp4\nProcessing video 486.mp4\nProcessing video 327.mp4\nProcessing video 196.mp4\nProcessing video 27.mp4\nProcessing video 352.mp4\nProcessing video 109.mp4\nProcessing video 428.mp4\nProcessing video 236.mp4\nProcessing video 182.mp4\nProcessing video 198.mp4\nProcessing video 119.mp4\nProcessing video 323.mp4\nProcessing video 100.mp4\nProcessing video 218.mp4\nProcessing video 358.mp4\nProcessing video 239.mp4\nProcessing video 49.mp4\nProcessing video 487.mp4\nProcessing video 178.mp4\nProcessing video 467.mp4\nProcessing video 488.mp4\nProcessing video 462.mp4\nProcessing video 281.mp4\nProcessing video 55.mp4\nProcessing video 15.mp4\nProcessing video 380.mp4\nProcessing video 35.mp4\nProcessing video 31.mp4\nProcessing video 152.mp4\nProcessing video 507.mp4\nProcessing video 231.mp4\nProcessing video 270.mp4\nProcessing video 29.mp4\nProcessing video 157.mp4\nProcessing video 463.mp4\nProcessing video 455.mp4\nProcessing video 7.mp4\nProcessing video 498.mp4\nProcessing video 397.mp4\nProcessing video 253.mp4\nProcessing video 23.mp4\nProcessing video 431.mp4\nProcessing video 174.mp4\nProcessing video 516.mp4\nProcessing video 141.mp4\nProcessing video 475.mp4\nProcessing video 422.mp4\nProcessing video 306.mp4\nProcessing video 13.mp4\nProcessing video 155.mp4\nProcessing video 255.mp4\nProcessing video 457.mp4\nProcessing video 211.mp4\nProcessing video 496.mp4\nProcessing video 492.mp4\nProcessing video 249.mp4\nProcessing video 124.mp4\nProcessing video 311.mp4\nProcessing video 2.mp4\nProcessing video 89.mp4\nProcessing video 210.mp4\nProcessing video 173.mp4\nProcessing video 17.mp4\nProcessing video 34.mp4\nProcessing video 244.mp4\nProcessing video 94.mp4\nProcessing video 410.mp4\nProcessing video 458.mp4\nProcessing video 440.mp4\nProcessing video 228.mp4\nProcessing video 25.mp4\nProcessing video 20.mp4\nProcessing video 417.mp4\nProcessing video 91.mp4\nProcessing video 88.mp4\nProcessing video 477.mp4\nProcessing video 342.mp4\nProcessing video 54.mp4\nProcessing video 33.mp4\nProcessing video 0.mp4\nProcessing video 461.mp4\nProcessing video 378.mp4\nProcessing video 110.mp4\nProcessing video 357.mp4\nProcessing video 497.mp4\nProcessing video 479.mp4\nProcessing video 14.mp4\nProcessing video 40.mp4\nProcessing video 160.mp4\nProcessing video 502.mp4\nProcessing video 339.mp4\nProcessing video 266.mp4\nProcessing video 460.mp4\nProcessing video 213.mp4\nProcessing video 130.mp4\nProcessing video 465.mp4\nProcessing video 408.mp4\nProcessing video 476.mp4\nProcessing video 136.mp4\nProcessing video 286.mp4\nProcessing video 104.mp4\nProcessing video 243.mp4\nProcessing video 325.mp4\nProcessing video 63.mp4\nProcessing video 481.mp4\nProcessing video 420.mp4\nProcessing video 194.mp4\nProcessing video 513.mp4\nProcessing video 112.mp4\nProcessing video 316.mp4\nProcessing video 39.mp4\nProcessing video 472.mp4\nProcessing video 411.mp4\nProcessing video 1.mp4\nProcessing video 47.mp4\nProcessing video 78.mp4\nProcessing video 219.mp4\nProcessing video 510.mp4\nProcessing video 280.mp4\nProcessing video 153.mp4\nProcessing video 203.mp4\nProcessing video 77.mp4\nProcessing video 107.mp4\nProcessing video 132.mp4\nProcessing video 19.mp4\nProcessing video 223.mp4\nProcessing video 195.mp4\nProcessing video 66.mp4\nProcessing video 275.mp4\nProcessing video 436.mp4\nProcessing video 385.mp4\nProcessing video 300.mp4\nProcessing video 200.mp4\nProcessing video 128.mp4\nProcessing video 68.mp4\nProcessing video 285.mp4\nProcessing video 495.mp4\nProcessing video 87.mp4\nProcessing video 421.mp4\nProcessing video 202.mp4\nProcessing video 369.mp4\nProcessing video 382.mp4\nProcessing video 214.mp4\nProcessing video 326.mp4\nProcessing video 359.mp4\nProcessing video 190.mp4\nProcessing video 381.mp4\nProcessing video 197.mp4\nProcessing video 505.mp4\nProcessing video 127.mp4\nProcessing video 331.mp4\nProcessing video 309.mp4\nProcessing video 186.mp4\nProcessing video 418.mp4\nProcessing video 435.mp4\nProcessing video 424.mp4\nProcessing video 83.mp4\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"test_features, test_ids, test_filenames = get_test_data()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T11:18:02.652128Z","iopub.execute_input":"2025-06-01T11:18:02.652441Z","iopub.status.idle":"2025-06-01T11:18:04.528080Z","shell.execute_reply.started":"2025-06-01T11:18:02.652422Z","shell.execute_reply":"2025-06-01T11:18:04.527498Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"test_model = trainer.model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T11:18:04.529119Z","iopub.execute_input":"2025-06-01T11:18:04.529302Z","iopub.status.idle":"2025-06-01T11:18:04.532793Z","shell.execute_reply.started":"2025-06-01T11:18:04.529287Z","shell.execute_reply":"2025-06-01T11:18:04.532172Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"test()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T11:25:05.497059Z","iopub.execute_input":"2025-06-01T11:25:05.497353Z","iopub.status.idle":"2025-06-01T11:25:12.770855Z","shell.execute_reply.started":"2025-06-01T11:25:05.497335Z","shell.execute_reply":"2025-06-01T11:25:12.770352Z"}},"outputs":[],"execution_count":45}]}